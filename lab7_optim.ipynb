{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CSC-52081-EP Lab7: Optimization - CEM / ES\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jeremiedecock/polytechnique-csc-52081-ep-2025-students/refs/heads/main/assets/logo.jpg\" style=\"float: left; width: 15%\" />\n",
    "\n",
    "[CSC-52081-EP-2025](https://moodle.polytechnique.fr/course/view.php?id=19336) Lab session #7\n",
    "\n",
    "2019-2025 Jérémie Decock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jeremiedecock/polytechnique-csc-52081-ep-2025-students/blob/main/lab7_optim.ipynb)\n",
    "\n",
    "[![My Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jeremiedecock/polytechnique-csc-52081-ep-2025-students/main?filepath=lab7_optim.ipynb)\n",
    "\n",
    "[![NbViewer](https://raw.githubusercontent.com/jupyter/design/main/logos/Badges/nbviewer_badge.svg)](https://nbviewer.jupyter.org/github/jeremiedecock/polytechnique-csc-52081-ep-2025-students/blob/main/lab7_optim.ipynb)\n",
    "\n",
    "[![Local](https://img.shields.io/badge/Local-Save%20As...-blue)](https://github.com/jeremiedecock/polytechnique-csc-52081-ep-2025-students/raw/main/lab7_optim.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "In the previous lab we studied a method that allowed us to apply reinforcement learning in continuous state spaces and/or continuous action spaces.\n",
    "We used REINFORCE, a *Policy gradient* method that directly optimize the parametric policy $\\pi_{\\theta}$.\n",
    "The parameter $\\theta$ was iteratively updated toward a local maximum of the total expected reward $J(\\theta)$ using a gradient ascent method:\n",
    "$$\\theta \\leftarrow \\theta + \\alpha \\nabla_{\\theta}J(\\theta)$$\n",
    "A convenient analytical formulation of $\\nabla_{\\theta}J(\\theta)$ was obtained thanks to the *Policy Gradient theorem*:\n",
    "\n",
    "$$\\nabla_\\theta J(\\theta) = \\nabla_\\theta V^{\\pi_\\theta}(s) = \\mathbb{E}_{\\pi_\\theta} \\left[\\nabla_\\theta \\log \\pi_\\theta (s,a) Q^{\\pi_\\theta}(s,a) \\right].$$\n",
    "However, gradient ascent methods may have a slow convergence and will only found a local optimum.\n",
    "Moreover, this approach requires an analytical formulation of $\\nabla_\\theta \\log \\pi_\\theta (s,a)$ which is not always known (when something else than a neural networks is used for the agent's policy).\n",
    "\n",
    "Direct Policy Search methods using gradient free optimization procedures like Evolution Strategies or Cross Entropy Method (CEM) are interesting alternatives to Policy Gradient algorithms.\n",
    "They can be successfully applied as long as the $\\pi_\\theta$ policy has no more than few hundreds of parameters.\n",
    "Moreover, these method can solve complex problems that cannot be modeled as Markov Decision Processes.\n",
    "\n",
    "As for previous Reinforcement Learning labs, we will use standard problems provided by Gymnasium suite.\n",
    "Especially, we will try to solve the LunarLander-v2 problem (https://gymnasium.farama.org/environments/box2d/lunar_lander/) which offers both continuous space and action states.\n",
    "\n",
    "As for previous labs, you can either:\n",
    "- open, edit and execute the notebook in *Google Colab* following this link: https://colab.research.google.com/github/jeremiedecock/polytechnique-csc-52081-ep-2025-students/blob/main/lab7_optim.ipynb ; this is the **recommended** choice as you have nothing to install on your computer\n",
    "- open, edit and execute the notebook in *MyBinder* (if for any reason the Google Colab solution doesn't work): https://mybinder.org/v2/gh/jeremiedecock/polytechnique-csc-52081-ep-2025-students/main?filepath=lab7_optim.ipynb\n",
    "- download, edit and execute the notebook on your computer if Python3 and JypyterLab are already installed: https://github.com/jeremiedecock/polytechnique-csc-52081-ep-2025-students/raw/main/lab7_optim.ipynb\n",
    "\n",
    "If you work with Google Colab or MyBinder, **remember to save or download your work regularly or you may lose it!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Lab Submission\n",
    "\n",
    "Please submit your completed notebook in [Moodle : \"Lab 7 - Submission\"](https://moodle.polytechnique.fr/course/section.php?id=66535).\n",
    "\n",
    "### Submission Guidelines\n",
    "\n",
    "1. **File Naming:** Rename your notebook as follows: **`firstname_lastname-07.ipynb`** where `firstname` and `lastname` match your email address. *Example: `jesse_read-07.ipynb`*\n",
    "2. **Clear Output Cells:** To reduce file size (**must be under 500 KB**), clear all output cells before submitting. This includes rendered images, videos, plots, and dataframes...\n",
    "   - **JupyterLab:**\n",
    "     - Click **\"Kernel\" → \"Restart Kernel and Clear Outputs of All Cells...\"**\n",
    "     - Then go to **\"File\" → \"Save Notebook As...\"**\n",
    "   - **Google Colab:**\n",
    "     - Click **\"Edit\" → \"Clear all outputs\"**\n",
    "     - Then go to **\"File\" → \"Download\" → \"Download.ipynb\"**\n",
    "   - **VSCode:**\n",
    "     - Click **\"Clear All Outputs\"**\n",
    "     - Then **save your file**\n",
    "3. **Upload Your File:** Only **`.ipynb`** files are accepted.\n",
    "\n",
    "**Note:** Bonus parts (if any) are optional, as their name suggests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Python environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook relies on several libraries including `gymnasium`, `numpy`, `pandas`, `seaborn`, `imageio`, `pygame` and `cma`.\n",
    "A complete list of dependencies can be found in the provided [requirements-lab7.txt](https://raw.githubusercontent.com/jeremiedecock/polytechnique-csc-52081-ep-2025-students/main/requirements-lab7.txt) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you use Google Colab\n",
    "\n",
    "Execute the next cell to install required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xt66Z85AmOI2",
    "outputId": "bd7a6b75-ad3c-4be1-d560-8239fbc0e9d2"
   },
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "\n",
    "def is_colab():\n",
    "    return \"google.colab\" in sys.modules\n",
    "\n",
    "def run_subprocess_command(cmd):\n",
    "    # run the command\n",
    "    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "    # print the output\n",
    "    for line in process.stdout:\n",
    "        print(line.decode().strip())\n",
    "\n",
    "if is_colab():\n",
    "    run_subprocess_command(\"apt install swig xvfb x11-utils\")\n",
    "    run_subprocess_command(\"pip install gymnasium[box2d] pyvirtualdisplay cma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJfFvm-4mOI2"
   },
   "outputs": [],
   "source": [
    "#! apt install xvfb x11-utils && pip install gymnasium pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have downloaded the notebook on your computer and execute it in your own Python environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up the necessary dependencies, first download the [requirements-lab7.txt](https://raw.githubusercontent.com/jeremiedecock/polytechnique-csc-52081-ep-2025-students/main/requirements-lab7.txt) file and ensure it is located in the same directory as this notebook. Next, run the following command to establish a [Python virtual environment (venv)](https://docs.python.org/3/library/venv.html) that includes all the essential libraries for this lab.\n",
    "\n",
    "#### On Posix systems (Linux, MacOSX, WSL, ...)\n",
    "\n",
    "```bash\n",
    "deactivate\n",
    "python3 -m venv env-lab7\n",
    "source env-lab7/bin/activate\n",
    "python3 -m pip install --upgrade pip\n",
    "python3 -m pip install -r requirements-lab7.txt\n",
    "```\n",
    "\n",
    "#### On Windows\n",
    "\n",
    "```bash\n",
    "deactivate\n",
    "python3 -m venv env-lab7\n",
    "env\\Scripts\\activate.bat\n",
    "python3 -m pip install --upgrade pip\n",
    "python3 -m pip install -r requirements-lab7.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Run CSC-52081-EP notebooks locally in a dedicated Docker container\n",
    "\n",
    "If you are familiar with Docker, an image is available on Docker Hub for this lab:\n",
    "\n",
    "```bash\n",
    "docker run -it --rm -p 8888:8888 -v \"${PWD}\":/home/jovyan/work jdhp/inf581-lab7:latest\n",
    "```\n",
    "\n",
    "If you encounter an error during the notebook's execution indicating that writing a file is not possible, this issue may stem from the user ID within the container lacking the necessary permissions in the project directory. This problem can be resolved by modifying the directory's permissions, for example, using the command:\n",
    "\n",
    "```bash\n",
    "chmod 777 .\n",
    "rm lab7_*.gif\n",
    "rm lab7_*.png\n",
    "rm *.pth\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import json\n",
    "import time\n",
    "from typing import List, Tuple, Deque, Optional, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "#from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Gymnasium rendering wrapper to visualize environments as GIF images within the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAFnXFZcrr-9"
   },
   "outputs": [],
   "source": [
    "# To display GIF images in the notebook\n",
    "\n",
    "import imageio     # To render episodes in GIF images (otherwise there would be no render on Google Colab)\n",
    "                   # C.f. https://stable-baselines.readthedocs.io/en/master/guide/examples.html#bonus-make-a-gif-of-a-trained-agent\n",
    "import IPython\n",
    "from IPython.display import Image\n",
    "\n",
    "if is_colab():\n",
    "    import pyvirtualdisplay\n",
    "\n",
    "    _display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
    "                                        size=(1400, 900))\n",
    "    _ = _display.start()\n",
    "\n",
    "class RenderWrapper:\n",
    "    def __init__(self, env, force_gif=False):\n",
    "        self.env = env\n",
    "        self.force_gif = force_gif\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.images = []\n",
    "\n",
    "    def render(self):\n",
    "        if not is_colab():\n",
    "            self.env.render()\n",
    "            time.sleep(1./60.)\n",
    "\n",
    "        if is_colab() or self.force_gif:\n",
    "            img = self.env.render()         # Assumes env.render_mode == 'rgb_array'\n",
    "            self.images.append(img)\n",
    "\n",
    "    def make_gif(self, filename=\"render\"):\n",
    "        if is_colab() or self.force_gif:\n",
    "            imageio.mimsave(filename + '.gif', [np.array(img) for i, img in enumerate(self.images) if i%2 == 0], fps=29, loop=0)\n",
    "            return Image(open(filename + '.gif','rb').read())\n",
    "\n",
    "    @classmethod\n",
    "    def register(cls, env, force_gif=False):\n",
    "        env.render_wrapper = cls(env, force_gif=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
